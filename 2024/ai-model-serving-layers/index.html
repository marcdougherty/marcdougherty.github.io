<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=dark data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>AI model serving layers &#183; Marc Dougherty</title>
<meta name=title content="AI model serving layers &#183; Marc Dougherty"><link rel=canonical href=https://www.marcdougherty.com/2024/ai-model-serving-layers/><link type=text/css rel=stylesheet href=/css/main.bundle.min.1d8b820a57a192ce1bb9342d9dd1d66b0ffb9953b2faa5f7d0af952364b54857f002bd95c41f483b7beda5debdf1572876ee24b166e43a54d970d2079df6c8bb.css integrity="sha512-HYuCClehks4buTQtndHWaw/7mVOy+qX30K+VI2S1SFfwAr2VxB9IO3vtpd698Vcodu4ksWbkOlTZcNIHnfbIuw=="><script type=text/javascript src=/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.d6c35110b5d7df8014403fbb81cd21a9d89daf9eb586c936e585e9d04adc204dce554aa737f81e8c902b9dea9e67bd63a977b77dedefb8a39430581ebc519207.js integrity="sha512-1sNRELXX34AUQD+7gc0hqdidr561hsk25YXp0ErcIE3OVUqnN/gejJArneqeZ71jqXe3fe3vuKOUMFgevFGSBw==" data-copy data-copied></script><script src=/js/zoom.min.js></script><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:url" content="https://www.marcdougherty.com/2024/ai-model-serving-layers/"><meta property="og:site_name" content="Marc Dougherty"><meta property="og:title" content="AI model serving layers"><meta property="og:description" content="When it comes to AI, most of the discussion focuses on the model itself, but there’s an important decision that many organizations are overlooking - the choice of their AI model serving layer.
You can think of the model itself as a big bundle of data - many models are distributed as a compressed archive of files. To make the model useful, you need a way to query it - which is where model serving layers come in."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-08-01T00:00:00+00:00"><meta property="article:modified_time" content="2024-08-06T15:11:25-07:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="AI model serving layers"><meta name=twitter:description content="When it comes to AI, most of the discussion focuses on the model itself, but there’s an important decision that many organizations are overlooking - the choice of their AI model serving layer.
You can think of the model itself as a big bundle of data - many models are distributed as a compressed archive of files. To make the model useful, you need a way to query it - which is where model serving layers come in."><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Posts","name":"AI model serving layers","headline":"AI model serving layers","abstract":"When it comes to AI, most of the discussion focuses on the model itself, but there\u0026rsquo;s an important decision that many organizations are overlooking - the choice of their AI model serving layer.\nYou can think of the model itself as a big bundle of data - many models are distributed as a compressed archive of files. To make the model useful, you need a way to query it - which is where model serving layers come in.","inLanguage":"en","url":"https:\/\/www.marcdougherty.com\/2024\/ai-model-serving-layers\/","author":{"@type":"Person","name":"Marc Dougherty"},"copyrightYear":"2024","dateCreated":"2024-08-01T00:00:00\u002b00:00","datePublished":"2024-08-01T00:00:00\u002b00:00","dateModified":"2024-08-06T15:11:25-07:00","mainEntityOfPage":"true","wordCount":"827"}]</script><meta name=author content="Marc Dougherty"><link href=https://github.com/muncus rel=me><link href=https://twitter.com/muncus rel=me><link href=https://dev.to/muncus rel=me><link href=https://medium.com/@muncus rel=me><script src=/lib/jquery/jquery.slim.min.js integrity></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-31G86DYMCL"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-31G86DYMCL")</script><meta name=theme-color></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ class="text-base font-medium text-gray-500 hover:text-gray-900">Marc Dougherty</a></nav><nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12"><a href=/posts/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Blog</p></a><a href=/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Tags</p></a><a href=/archive/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Archive</p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="ltr:mr-14 rtl:ml-14 flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center space-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400" style=margin-right:5px><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 -mr-2 md:hidden"><label id=menu-button for=menu-controller class=block><input type=checkbox id=menu-controller class=hidden><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/posts/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Blog</p></a></li><li class=mt-1><a href=/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Tags</p></a></li><li class=mt-1><a href=/archive/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Archive</p></a></li></ul></div></label></div></div><div class="relative flex flex-col grow"><main id=main-content class=grow><article><header id=single_header class="mt-5 max-w-prose"><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">AI model serving layers</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime="2024-08-01 00:00:00 +0000 UTC">2024-08-01</time><span class="px-2 text-primary-500">&#183;</span><time datetime="2024-08-06 15:11:25 -0700 -0700">Updated: 2024-08-06</time><span class="px-2 text-primary-500">&#183;</span><span>827 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">4 mins</span></div><div class="flex flex-row flex-wrap items-center"></div></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-10"><details open class="toc-right mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#why-is-the-model-serving-layer-important>why is the model serving layer important?</a></li><li><a href=#telemetry>Telemetry</a></li><li><a href=#operability-and-tuning>Operability and tuning</a></li><li><a href=#recap>Recap</a></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#why-is-the-model-serving-layer-important>why is the model serving layer important?</a></li><li><a href=#telemetry>Telemetry</a></li><li><a href=#operability-and-tuning>Operability and tuning</a></li><li><a href=#recap>Recap</a></li></ul></nav></div></details></div></div><div class="min-w-0 min-h-0 max-w-fit"><details style=margin-left:0 class="mt-2 mb-5 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5"><summary class="py-1 text-lg font-semibold cursor-pointer bg-primary-200 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-primary-800 dark:text-neutral-100">AI productionization - This article is part of a series.</summary><div class="py-1 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600">Part : This Article</div></details><div class="article-content max-w-prose mb-20"><p>When it comes to AI, most of the discussion focuses on the model itself, but
there&rsquo;s an important decision that many organizations are overlooking - the
choice of their AI model serving layer.</p><p>You can think of the model itself as a big bundle of data - many models are
distributed as a compressed archive of files. To make the model useful, you need
a way to query it - which is where model serving layers come in.</p><p>While AI technology is still rapidly evolving, the APIs published by
<a href=https://platform.openai.com/docs/api-reference/introduction target=_blank>OpenAI</a> are
becoming broadly used by other model serving layers. Specifically the <a href=https://platform.openai.com/docs/guides/completions target=_blank>OpenAI
completion</a> and <a href=https://platform.openai.com/docs/guides/chat-completions target=_blank>chat
completion</a> APIs -
with chat completion being the preferred method.</p><p>vLLM is a popular serving tookit that provides an OpenAI compatible server built
into its <a href=https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html target=_blank><code>vllm serve</code>
command</a>,
and as a <a href=https://docs.vllm.ai/en/latest/serving/deploying_with_docker.html target=_blank>Docker
container</a>.</p><p>&#x1f917; <a href=http://huggingface.co target=_blank>HuggingFace</a> offers their <a href=https://huggingface.co/docs/text-generation-inference/main/en/index# target=_blank>Text Generation
Inference
API</a> (TGI)
as another competing API, with an open source <a href=https://github.com/huggingface/text-generation-inference target=_blank>API
implementation</a> that&rsquo;s
capable of serving most modern models. It supports chat-style interaction
through its <a href=https://huggingface.co/docs/text-generation-inference/main/en/messages_api#messages-api target=_blank>Messages
API</a>
for OpenAI-compatible chat completion.</p><p>The rest of this article discusses the similarities and differences of vLLM
and TGI. The topics discussed here would apply equally to any AI model serving
layer.</p><h2 class="relative group">why is the model serving layer important?<div id=why-is-the-model-serving-layer-important class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#why-is-the-model-serving-layer-important aria-label=Anchor>#</a></span></h2><p>The model serving layer determines how users can interact with your model, like
what kinds of inputs are accepted and how they need to be presented. There are a
bunch of different options for client libraries:</p><ul><li>OpenAI&rsquo;s client libraries work on any OpenAI-compatible model server</li><li>HuggingFace&rsquo;s TGI client (<code>hugginface-hub</code>) work for any
TGI-compatible server</li><li>Some hosted models (like Google&rsquo;s Gemini) have their own API and
associated client library</li><li>There are also frameworks like <a href=langchain.com>langchain</a> that
have support for many different LLM backends.</li></ul><p>Because this technology is evolving rapidly, I recommend choosing either the
OpenAI client (which has emerged as industry standard) or one of the multi-API
frameworks like langchain. This choice insulates you from changes in the
underlying APIs, and allow you to move between models (and model hosting
platforms!) with minimal updates to your codebase.</p><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M159.3 5.4c7.8-7.3 19.9-7.2 27.7.1 27.6 25.9 53.5 53.8 77.7 84 11-14.4 23.5-30.1 37-42.9 7.9-7.4 20.1-7.4 28 .1 34.6 33 63.9 76.6 84.5 118 20.3 40.8 33.8 82.5 33.8 111.9C448 404.2 348.2 512 224 512 98.4 512 0 404.1.0 276.5c0-38.4 17.8-85.3 45.4-131.7C73.3 97.7 112.7 48.6 159.3 5.4zM225.7 416c25.3.0 47.7-7 68.8-21 42.1-29.4 53.4-88.2 28.1-134.4-2.8-5.6-5.6-11.2-9.8-16.8l-50.6 58.8S180.8 199 175.1 192c-42 51.8-63.1 81.2-63.1 114.8C112 375.4 162.6 416 225.7 416z"/></svg>
</span></span><span class=dark:text-neutral-300><p>vLLM has <strong>two different</strong> API server implementations.
One is OpenAI compatible
(<a href=https://github.com/vllm-project/vllm/blob/main/vllm/entrypoints/openai/api_server.py target=_blank>
<code>vllm.entrypoints.openai.api_server</code></a>,
while the other is not
(<a href=https://github.com/vllm-project/vllm/blob/main/vllm/entrypoints/api_server.py target=_blank>
<code>vllm.entrypoints.api_server</code></a>).</p><p>The differences between the two are subtle so be careful!</p></span></div><p>While the client interface aspect may seem straightforward, there are some other
effects that are less apparent.</p><h2 class="relative group">Telemetry<div id=telemetry class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#telemetry aria-label=Anchor>#</a></span></h2><p>Telemetry from the model serving layer determines how much <em>visibility</em> you have
into the behavior of your model serving. Common telemetry signals include logs,
monitoring metrics and distributed traces.</p><p>Both vLLM and TGI provide metrics and tracing with
<a href=http://opentelemetry.org target=_blank>OpenTelemetry</a>, which is the industry standard. The
specific metrics and tracing data varies between the two.</p><p>I recommend serving the same model with both and exploring available monitoring
and trace data.</p><p>Logging is less standardized than metrics and tracing, but usually falls into
the broad categories of &ldquo;structured&rdquo; or &ldquo;unstructured&rdquo;. Structured logs are
commonly JSON objects, which logging backends can parse to make logs highly
searchable. Unstructured logs are treated as plain text, which may be more
difficult to search for specific strings.</p><p>When logging from a cloud provider, be mindful of how your hosting platform
interprets your logs. As an example, Google&rsquo;s Cloud Logging service attempts to
parse structured logs, if they are in the correct format, to set metadata fields
like log level (which it calls &lsquo;severity&rsquo;). Properly parsed log metadata makes
it easier to find errors when your service is misbehaving.</p><h2 class="relative group">Operability and tuning<div id=operability-and-tuning class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#operability-and-tuning aria-label=Anchor>#</a></span></h2><p>Most model serving layers provide comparable options for use of hardware
GPU/TPUs, quantizers, LoRA adapters, and batching. While exact support for
hardware and model serving may vary slightly between model servers, they are
unlikely to be a factor in your model server choice.</p><p>One notable difference is the server-side protection configuration available in
TGI. While most clients allow the user to set query parameters, TGI has the
ability to set <strong>maximums</strong> for many of these parameters, like input tokens, top
N, total input length, etc. These options are described in the <a href=https://huggingface.co/docs/text-generation-inference/main/en/basic_tutorials/launcher#maxconcurrentrequests target=_blank>TGI Options
documentation</a></p><p>These options ensure consistent treatment of all clients, and can help avoid a
<a href=https://learn.microsoft.com/en-us/azure/architecture/antipatterns/noisy-neighbor/noisy-neighbor target=_blank>&ldquo;noisy neighbor&rdquo;
problem</a>
when a model service has many clients.</p><p><code>MAX_CONCURRENT_REQUESTS</code> is particularly useful, as it allows busy models to
fail requests when overloaded - allowing the client to retry the request on
another instance, rather than waiting a long time for their request to be
processed by a busy instance.</p><p>I hope to see similar options appear in other frameworks soon. In the meantime,
I recommend choosing TGI as your model serving layer as it gives maximum control
over how the model service behaves in production.</p><p>As an added bonus, TGI also includes a <a href=https://github.com/huggingface/text-generation-inference/tree/main/benchmark target=_blank>benchmark
tool</a>,
so you can test out various settings before deploying them to production!</p><h2 class="relative group">Recap<div id=recap class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#recap aria-label=Anchor>#</a></span></h2><p>Model serving is an important consideration, and can have strong effects on how
your model behaves in production, and how well you can inspect the model&rsquo;s
behavior.</p></div><details style=margin-left:0 class="mt-2 mb-5 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5"><summary class="py-1 text-lg font-semibold cursor-pointer bg-primary-200 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-primary-800 dark:text-neutral-100">AI productionization - This article is part of a series.</summary><div class="py-1 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600">Part : This Article</div></details></div><script>var oid="views_posts/ai-model-serving.md",oid_likes="likes_posts/ai-model-serving.md"</script><script type=text/javascript src=/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2024
Marc Dougherty</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://www.marcdougherty.com/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body></html>